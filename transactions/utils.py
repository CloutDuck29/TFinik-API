import re, pdfplumber, logging
import datetime

logging.getLogger("pdfminer").setLevel(logging.ERROR)
logging.getLogger("pdfplumber").setLevel(logging.ERROR)

# --- –ü–ê–†–°–ï–† –¢-–ë–ê–ù–ö–ê ---
def parse_tbank_statement(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join(page.extract_text() or "" for page in pdf.pages)

    if not re.search(r'–¢-?–±–∞–Ω–∫', text, re.IGNORECASE):
        raise ValueError("‚ùå –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤—ã–ø–∏—Å–∫–æ–π –¢-–±–∞–Ω–∫–∞")

    m = re.search(r'–î–≤–∏–∂–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å (\d{2}\.\d{2}\.\d{4}) –ø–æ (\d{2}\.\d{2}\.\d{4})', text)
    start, end = m.groups() if m else (None, None)

    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    pat1 = re.compile(r'^(\d{2}\.\d{2}\.\d{4})\s+(\d{2}\.\d{2}\.\d{4})\s+([+\-][\d\s\.,]+)\s+‚ÇΩ\s+([+\-][\d\s\.,]+)\s+‚ÇΩ\s+(.+?)\s+(\d{4})$')
    pat2 = re.compile(r'^(\d{2}:\d{2})\s+(\d{2}:\d{2})\s+(.+)$')

    footer_patterns = [
        re.compile(r'^–ê–û ¬´–¢–ë–∞–Ω–∫', re.IGNORECASE),
        re.compile(r'^–ë–ò–ö', re.IGNORECASE),
        re.compile(r'^–ò–ù–ù', re.IGNORECASE),
        re.compile(r'^–ü–æ–ø–æ–ª–Ω–µ–Ω–∏—è[:\s]', re.IGNORECASE),
        re.compile(r'^–†–∞—Å—Ö–æ–¥[:\s]', re.IGNORECASE),
        re.compile(r'^–ò—Ç–æ–≥–æ', re.IGNORECASE),
        re.compile(r'^–° —É–≤–∞–∂–µ–Ω–∏–µ–º', re.IGNORECASE),
    ]

    txs = []
    clean = lambda s: float(s.replace(" ", "").replace(",", "."))
    i = 0
    while i < len(lines) - 1:
        m1 = pat1.match(lines[i])
        m2 = pat2.match(lines[i + 1])
        if m1 and m2:
            date_op, _, amt_op_raw, _, desc1, _ = m1.groups()
            time_op, _, desc2 = m2.groups()
            desc = f"{desc1} {desc2}"
            j = i + 2
            while j < len(lines):
                if pat1.match(lines[j]) or pat2.match(lines[j]) or any(p.search(lines[j]) for p in footer_patterns):
                    break
                desc += ' ' + lines[j]
                j += 1
            amount_value = clean(amt_op_raw)
            is_income = amount_value > 0

            txs.append({
                'date': date_op,
                'time': time_op,
                'amount': amount_value if is_income else -abs(amount_value),  # ‚úÖ
                'description': desc.strip(),
                'isIncome': is_income
            })
            i = j
        else:
            i += 1

    return start, end, categorize_tbank(txs)

def categorize_tbank(txs):
    rules = {
        '–ö–æ—Ñ–µ–π–Ω–∏':            [r'–∫–æ—Ñ–µ', r'–∫–æ—Ñ–µ–π–Ω—è', r'–∫–æ—Ñ–µ—à–æ–ø', r'cafe', r'coffee',
                               r'—à–æ–∫–æ–ª–∞–¥–Ω–∏—Ü–∞', r'–∫–æ—Ñ–µ–º–∞–Ω–∏—è', r'Coffeemania',
                               r'–¥–∞–±–ª–±–∏', r'DBL', r'DoubleB', r'—Å–∫—É—Ä–∞—Ç–æ–≤', r'skuratov',
                               r'—ç–Ω–∏—Ç–∞–π–º', r'entime', r'starbucks', r'—Å—Ç–∞—Ä–±–∞–∫—Å'],
        '–ú–∞–≥–∞–∑–∏–Ω—ã':           [r'krasnoe', r'–∫—Ä–∞—Å–Ω–æ–µ', r'beloye', r'–±–µ–ª–æ–µ', r'magnit', r'–º–∞–≥–Ω–∏—Ç',
                               r'–ø–æ–±–µ–¥–∞', r'pobeda', r'plaza', r'fixprice', r'—Ñ–∏–∫—Å –ø—Ä–∞–π—Å',
                               r'triumf', r'—Ç—Ä–∏—É–º—Ñ', r'bufet', r'–±—É—Ñ–µ—Ç', r'pek', r'–ø–µ–∫–∞—Ä—É—à–∫–∞',
                               r'prostor', r'–ø—Ä–æ—Å—Ç–æ—Ä', r'ozon', r'ozon\.ru', r'wildberries',
                               r'–≤–∞–ª–¥–±–µ—Ä—Ä–∏—Å', r'avito', r'–ø—è—Ç(—ë|–µ)—Ä–æ—á–∫–∞', r'–∞—à–∞–Ω',
                               r'–¥(–∏|–∏)?–∫—Å–∏', r'–ª–µ–Ω—Ç–∞', r'okey', r'–æ–∫–µ–π', r'\bip\b',
                                r'—è—Ä—á–µ!?', r'yarche',
                               r'GLOBUS'
                                r'–º–∞—Ä–∏—è[\s\-]?—Ä–∞', r'maria[\s\-]?ra',
                                r'–º–æ–Ω–µ—Ç–∫–∞', r'monetka',
                                r'–∫–æ–º–∞–Ω–¥–æ—Ä', r'komandor',
                                r'—Ö–æ–ª–∏–¥–µ–π', r'holiday',
                                r'–±–∞—Ç–æ–Ω', r'baton',
                                r'–∞–Ω–∏–∫—Å', r'aniks',
                                r'—Å–ª–∞—Ç–∞', r'slata',
                                r'—è—Ä–º–∞—Ä–∫–∞',
                                r'–∫–æ–Ω—Ç–∏–Ω–µ–Ω—Ç', r'kontinent',
                                r'–ø—á[–µ—ë]–ª–∫–∞', r'pchelk',
                                r'dns[-\s]?shop', r'\bdns\b',
                                r'citilink', r'—Å–∏—Ç–∏–ª–∏–Ω–∫',
                                r'leroy[\s\-]?merlin', r'–ª–µ—Ä—É–∞',
                                r'\bobi\b', r'–æ–±–∏',
                                r'trial', r'sport'],

        '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç':          ['metro', 'omka', '–æ–º–∫–∞', 'Transport'],
        '–î–æ—Å—Ç–∞–≤–∫–∞':       [r'yandex', r'—è–Ω–¥–µ–∫—Å', r'eda', r'–µ–¥–∞', r'samokat', r'—Å–∞–º–æ–∫–∞—Ç',
                               r'delivery', r'–¥–æ—Å—Ç–∞–≤–∫–∞', r'uber', r'ubereats', r'food',
                               r'–¥–æ—Å—Ç–∞–≤–∫[ae]', r'–¥–µ–ª–∏–≤–µ—Ä–∏'],
        '–†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è':        [r'ivi', r'okko', r'kinopoisk', r'netflix', r'–∫–∏–Ω–æ–ø–æ–∏—Å–∫'],
        '–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ':         [r'–ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ', r'–≤–Ω–µ—Å–µ–Ω–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö', r'cashback', r'–∫—ç—à–±—ç–∫'],
        '–ñ–ö–•':     [r'zhku', r'–∂–∫—Ö', r'kvartplata', r'–∫–≤–∞—Ä—Ç–ø–ª–∞—Ç–∞', r'dsos', r'–∫–æ–º–º—É–Ω–∞–ª'],
        '–ü–µ—Ä–µ–≤–æ–¥—ã':           [r'–ø–µ—Ä–µ–≤–æ–¥'],
    }
    regex = {cat: [re.compile(p, re.IGNORECASE) for p in pats] for cat, pats in rules.items()}
    for tx in txs:
        tx['category'] = '–î—Ä—É–≥–∏–µ'
        for cat, patterns in regex.items():
            if any(p.search(tx['description']) for p in patterns):
                tx['category'] = cat
                break
    return txs

# --- –ü–ê–†–°–ï–† –°–ë–ï–†–ë–ê–ù–ö–ê ---
def parse_sber_statement(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        texts = [page.extract_text() for page in pdf.pages if page.extract_text()]
        full_text = "\n".join(texts)
        lowered_full = full_text.lower()
        first_page = texts[0].lower() if texts else ""

    # üî• 1. –ó–∞–ø—Ä–µ—â–∞–µ–º —á—É–∂–∏–µ –±–∞–Ω–∫–∏
    if any(foreign in first_page for foreign in ["—Ç–∏–Ω—å–∫–æ—Ñ—Ñ", "tinkoff", "—Ç-–±–∞–Ω–∫", "t-bank"]):
        raise ValueError("‚ùå –≠—Ç–æ –Ω–µ –≤—ã–ø–∏—Å–∫–∞ –°–±–µ—Ä–±–∞–Ω–∫–∞ (–æ–±–Ω–∞—Ä—É–∂–µ–Ω –¥—Ä—É–≥–æ–π –±–∞–Ω–∫ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ)")

    # ‚úÖ 2. –ì–∏–±–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –°–±–µ—Ä–∞ ‚Äî –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫
    sber_ok = any(p in first_page for p in [
        "—Å–±–µ—Ä–±–∞–Ω–∫", "–≤—ã–ø–∏—Å–∫–∞ –ø–æ —Å—á–µ—Ç—É", "–¥–µ–±–µ—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∞", "–∏—Ç–æ–≥–æ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º"
    ])
    if not sber_ok:
        raise ValueError("‚ùå –≠—Ç–æ –Ω–µ –≤—ã–ø–∏—Å–∫–∞ –°–±–µ—Ä–±–∞–Ω–∫–∞ (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)")


    # üîé –ò—â–µ–º –ø–µ—Ä–∏–æ–¥ –≤—ã–ø–∏—Å–∫–∏ (–¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è)
    m = re.search(r'–ò—Ç–æ–≥–æ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º —Å (\d{2}\.\d{2}\.\d{4}) –ø–æ (\d{2}\.\d{2}\.\d{4})', full_text)
    if not m:
        m = re.search(r'–î–≤–∏–∂–µ–Ω–∏–µ —Å—Ä–µ–¥—Å—Ç–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å (\d{2}\.\d{2}\.\d{4}) –ø–æ (\d{2}\.\d{2}\.\d{4})', full_text)
    start, end = m.groups() if m else (None, None)

    lines = full_text.split('\n')
    operation_lines = [line.strip() for line in lines if re.match(r"\d{2}\.\d{2}\.\d{4}", line.strip())]

    transactions = []
    for line in operation_lines:
        match = re.match(r"(\d{2}\.\d{2}\.\d{4})\s+\d{2}:\d{2}\s+\d+\s+(.*?)\s+([+\-]?\d[\d\s\xa0]*,\d{2})", line)
        if match:
            date, description, amount = match.groups()
            amount = float(amount.replace("\xa0", "").replace(" ", "").replace(",", "."))
            is_income = amount > 0

            transactions.append({
                "date": datetime.datetime.strptime(date, "%d.%m.%Y").date().isoformat(),
                "time": None,
                "amount": amount if is_income else -abs(amount),  # ‚úÖ
                "description": description.strip(),
                "isIncome": is_income
            })
    return start, end, categorize_sber(transactions)


def categorize_sber(txs):
    mapping = {
        "–≤–Ω–µ—Å–µ–Ω–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö": "–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ",
        "–ø—Ä–æ—á–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∫–∞—Ä—Ç—É": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–ø–µ—Ä–µ–≤–æ–¥ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–º—É –ª–∏—Ü—É": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–ø–µ—Ä–µ–≤–æ–¥ –°–ë–ü": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–æ–ø–ª–∞—Ç–∞ –ø–æ —Ä–µ–∫–≤–∏–∑–∏—Ç–∞–º": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–ø–µ—Ä–µ–≤–æ–¥ —Å –∫–∞—Ä—Ç—ã": "–ü–µ—Ä–µ–≤–æ–¥—ã",
        "–æ—Ç–¥—ã—Ö –∏ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è": "–†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è",
        "—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç": "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç",
        "–º–∞–≥–∞–∑–∏–Ω": "–ú–∞–≥–∞–∑–∏–Ω—ã",
        "–∫–∞—Ñ–µ": "–ö–æ—Ñ–µ–π–Ω–∏",
        "—Ä–µ—Å—Ç–æ—Ä–∞–Ω": "–ö–æ—Ñ–µ–π–Ω–∏",
        "–∫–æ—Ñ–µ–π–Ω—è": "–ö–æ—Ñ–µ–π–Ω–∏",
        "–¥–æ—Å—Ç–∞–≤–∫–∞": "–î–æ—Å—Ç–∞–≤–∫–∞",
        "—è–Ω–¥–µ–∫—Å –µ–¥–∞": "–î–æ—Å—Ç–∞–≤–∫–∞",
        "delivery": "–î–æ—Å—Ç–∞–≤–∫–∞",
        "–∂–∫—É": "–ñ–ö–•",
    }

    def remap(description: str) -> str:
        desc = description.lower()
        for key in mapping:
            if key in desc:
                return mapping[key]
        return "–î—Ä—É–≥–∏–µ"

    for tx in txs:
        tx['category'] = remap(tx['description'])
    return txs

# --- –û–ë–©–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø BACKEND ---
def parse_statement(pdf_path, bank: str):
    bank = bank.lower()
    if bank in ("tinkoff", "tbank"):
        return parse_tbank_statement(pdf_path)
    elif bank == "sber":
        return parse_sber_statement(pdf_path)
    else:
        raise ValueError(f"‚ùå Unsupported bank: {bank}")
